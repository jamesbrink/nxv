name: Publish Index

# This workflow updates the nxv package index from nixpkgs
# It runs on a schedule or can be triggered manually

on:
  # Run every 6 hours to keep index fresh
  schedule:
    - cron: '0 */6 * * *'

  # Allow manual triggering
  workflow_dispatch:

concurrency:
  group: publish-index
  cancel-in-progress: false  # Let runs complete, queue new ones

env:
  CARGO_TERM_COLOR: always
  # Index is stored in a GitHub release with this tag
  # Forks can override INDEX_URL_PREFIX via repository variable (Settings > Secrets and variables > Actions > Variables)
  INDEX_RELEASE_TAG: index-latest
  INDEX_URL_PREFIX: ${{ vars.INDEX_URL_PREFIX || format('https://github.com/{0}/releases/download/index-latest', github.repository) }}

jobs:
  update-index:
    name: Update Package Index
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout nxv
        uses: actions/checkout@v4

      - name: Install Nix
        uses: cachix/install-nix-action@v30
        with:
          github_access_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Cachix
        uses: cachix/cachix-action@v16
        with:
          name: nxv
          authToken: '${{ secrets.CACHIX_AUTH_TOKEN }}'

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-indexer-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-indexer-

      - name: Build nxv with indexer
        run: cargo build --release --features indexer

      # Download existing index BEFORE cloning nixpkgs so we can determine clone depth
      - name: Download existing index
        id: download-index
        continue-on-error: true
        run: |
          set -euo pipefail
          mkdir -p ~/.local/share/nxv
          echo "Downloading existing index from ${INDEX_URL_PREFIX}..."

          if curl -sSfL "${INDEX_URL_PREFIX}/index.db.zst" -o ~/.local/share/nxv/index.db.zst; then
            echo "Downloaded index.db.zst ($(du -h ~/.local/share/nxv/index.db.zst | cut -f1))"
            if zstd -d ~/.local/share/nxv/index.db.zst -o ~/.local/share/nxv/index.db; then
              rm ~/.local/share/nxv/index.db.zst
              echo "Decompressed to index.db ($(du -h ~/.local/share/nxv/index.db | cut -f1))"
              echo "index_exists=true" >> $GITHUB_OUTPUT
            else
              echo "Failed to decompress index.db.zst"
              rm -f ~/.local/share/nxv/index.db.zst ~/.local/share/nxv/index.db
              echo "index_exists=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "No existing index found (this is normal for first run)"
            echo "index_exists=false" >> $GITHUB_OUTPUT
          fi

          # Also download bloom filter if available
          if curl -sSfL "${INDEX_URL_PREFIX}/bloom.bin" -o ~/.local/share/nxv/bloom.bin; then
            echo "Downloaded bloom.bin ($(du -h ~/.local/share/nxv/bloom.bin | cut -f1))"
          else
            echo "No existing bloom filter found"
            rm -f ~/.local/share/nxv/bloom.bin
          fi

          # Show what we have
          echo "Contents of ~/.local/share/nxv:"
          ls -la ~/.local/share/nxv/ || echo "(empty)"

      - name: Determine clone depth
        id: clone-strategy
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # We require an existing index for incremental updates
          # Full rebuilds take days and should be done locally, not in CI

          if [ "${{ steps.download-index.outputs.index_exists }}" != "true" ]; then
            echo "::error::No existing index available. Full rebuilds must be done locally (takes days)."
            echo "Upload an initial index to the index-latest release first."
            exit 1
          fi

          # Get last indexed commit from the database
          LAST_COMMIT=$(./target/release/nxv stats 2>/dev/null | grep "Last indexed commit" | awk '{print $4}')
          echo "Last indexed commit: ${LAST_COMMIT:-unknown}"

          if [ -z "$LAST_COMMIT" ]; then
            echo "::error::Could not determine last indexed commit from database."
            exit 1
          fi

          # Fetch the current nixpkgs-unstable channel commit
          # This ensures we only index tested commits with binary cache availability
          echo "Fetching nixpkgs-unstable channel commit..."
          UNSTABLE_COMMIT=$(curl -sL https://channels.nixos.org/nixpkgs-unstable/git-revision)
          echo "nixpkgs-unstable commit: ${UNSTABLE_COMMIT}"
          echo "unstable_commit=${UNSTABLE_COMMIT}" >> $GITHUB_OUTPUT

          # Use GitHub API to count commits between last indexed and nixpkgs-unstable
          echo "Querying GitHub API for commit count..."
          AHEAD=$(gh api "repos/NixOS/nixpkgs/compare/${LAST_COMMIT}...${UNSTABLE_COMMIT}" --jq '.ahead_by' 2>/dev/null || echo "")

          if [ -z "$AHEAD" ] || [ "$AHEAD" = "null" ]; then
            echo "::error::GitHub API failed or commit ${LAST_COMMIT} not found in nixpkgs-unstable."
            echo "The indexed commit may have been garbage collected or rebased out."
            exit 1
          fi

          if [ "$AHEAD" = "0" ]; then
            echo "Index is already up to date!"
            echo "depth=0" >> $GITHUB_OUTPUT
            echo "strategy=skip" >> $GITHUB_OUTPUT
            exit 0
          fi

          DEPTH=$((AHEAD + 10))
          echo "Commits ahead: ${AHEAD}, clone depth: ${DEPTH}"
          echo "depth=${DEPTH}" >> $GITHUB_OUTPUT
          echo "strategy=shallow" >> $GITHUB_OUTPUT

      - name: Skip if already up to date
        if: ${{ steps.clone-strategy.outputs.strategy == 'skip' }}
        run: |
          echo "Index is already up to date, nothing to do!"
          echo "## Index Already Current" >> $GITHUB_STEP_SUMMARY
          echo "The index is already up to date with nixpkgs-unstable. No update needed." >> $GITHUB_STEP_SUMMARY

      - name: Clone nixpkgs (shallow)
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        run: |
          UNSTABLE_COMMIT="${{ steps.clone-strategy.outputs.unstable_commit }}"
          echo "Performing shallow clone to nixpkgs-unstable commit ${UNSTABLE_COMMIT}..."

          # Clone master branch with enough depth, then checkout the unstable commit
          git clone --depth ${{ steps.clone-strategy.outputs.depth }} \
            --single-branch --branch nixpkgs-unstable \
            https://github.com/NixOS/nixpkgs.git nixpkgs

          # Ensure we have the unstable commit and check it out
          git -C nixpkgs fetch origin ${UNSTABLE_COMMIT} --depth 1 || true
          git -C nixpkgs checkout ${UNSTABLE_COMMIT}

          echo "Clone complete at nixpkgs-unstable commit:"
          git -C nixpkgs rev-parse HEAD

      - name: Run indexer
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        run: ./target/release/nxv index --nixpkgs-path ./nixpkgs

      - name: Generate publishable artifacts
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        env:
          NXV_SECRET_KEY: ${{ secrets.NXV_SIGNING_KEY }}
        run: |
          ./target/release/nxv publish \
            --output ./publish \
            --url-prefix "${INDEX_URL_PREFIX}" \
            --sign

      - name: Upload workflow artifacts
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        uses: actions/upload-artifact@v4
        with:
          name: nxv-index
          path: publish/
          retention-days: 7

      - name: Upload to GitHub Release
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          # Check if release exists, create if not
          if ! gh release view "$INDEX_RELEASE_TAG" > /dev/null 2>&1; then
            echo "Creating release $INDEX_RELEASE_TAG..."
            gh release create "$INDEX_RELEASE_TAG" \
              --title "Package Index" \
              --notes "nxv package index files. Updated automatically." \
              --latest=false
          fi

          # Upload files (--clobber overwrites existing assets)
          echo "Uploading index files to release..."
          gh release upload "$INDEX_RELEASE_TAG" \
            publish/index.db.zst \
            publish/bloom.bin \
            publish/manifest.json \
            publish/manifest.json.minisig \
            --clobber

      - name: Summary
        if: ${{ steps.clone-strategy.outputs.strategy != 'skip' }}
        run: |
          echo "## Index Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Clone depth:** ${{ steps.clone-strategy.outputs.depth }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Index size:** $(du -h publish/index.db.zst | cut -f1)" >> $GITHUB_STEP_SUMMARY
          echo "- **Bloom filter size:** $(du -h publish/bloom.bin 2>/dev/null | cut -f1 || echo 'N/A')" >> $GITHUB_STEP_SUMMARY
          echo "- **Release:** [$INDEX_RELEASE_TAG](https://github.com/${{ github.repository }}/releases/tag/$INDEX_RELEASE_TAG)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat publish/manifest.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
